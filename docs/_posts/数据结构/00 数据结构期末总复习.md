---
title: 数据结构期末总复习
draft: true
date: 2020-12-29
tags:
  - 数据结构
--- 

> 数据结构考试梳理

<!-- more -->
<!-- 
::: note
前天晚上抽时间把数据结构书过了一遍，还是有挺多不太熟练的地方，这个东西还需要一直巩固，就那么一点点东西而已，code 过程中遇到就再看看，数据结构工作前烂熟于心才对
所以我不厌其烦的 多总结，多删，多重写，也是有意义的
一年内的打字速度快了不少，基本和想的速度差不多了，多写的话逻辑也会变清晰的吧，可能
还有！我的博客是给我自己看的，所以不必拘泥于条条框框，我想写什么写什么，想怎么写怎么写，嘿嘿嘿

以下内容在我的其他文章中也会出现，毕竟不可能也不应该纪念大学上完还没有一份完完整整的数据结构笔记对吧，反正不打游戏的话时间会有很多，造就完事
::: -->

一位优秀的挖坑不填选手罢了，再把那份题看一看就没事了

## 二叉树的复原

哇咔咔，之前过了一遍，但是我发现根本没记住（循环体验学到新知识的快感？）

[甩个之前的链接](https://konng.now.sh/posts/2020/11/30/_05-binary-tree.html#%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%87%8D%E6%9E%84)

这种了解过的就先不看了

## 哈夫曼树

树的一类应用

一直都在听这个名词：哈夫曼编码，听上去很厉害的样式，也没有认认真真的总结一遍

以下是对 这个人上人未知名词的探索

相关历史信息百度里有

[百度百科跳转](https://baike.baidu.com/item/%E5%93%88%E5%A4%AB%E6%9B%BC%E6%A0%91)

### 哈夫曼树定义

给定 N 个权值作为 N 个叶子结点，构造一棵二叉树，若该树的带权路径长度达到最小，

称这样的二叉树为最优二叉树，也称为哈夫曼树 (Huffman Tree)。哈夫曼树是带权路径长度和最短的树

（所谓树的带权路径长度，就是树中所有的叶结点的权值乘上其到根结点的路径长度）

[相关基本术语](https://baike.baidu.com/item/%E5%93%88%E5%A4%AB%E6%9B%BC%E6%A0%91#4)

举例：

![demo](https://images2017.cnblogs.com/blog/1060770/201801/1060770-20180117231555412-1315284149.png)

对 a: WPL = 7×2 + 5×2 + 2×2 + 4×2 = 36；
对 b: WPL = 7×3 + 5×3 + 2×1 + 4×2 = 46;
对 c: WPL = 7×1 + 5×2 + 2×3 + 4×3  = 35;
 
c 中 WPL 最小，可以验证，它就是赫夫曼树，而 a 和 b 都不是赫夫曼树

对于同一组权值的叶结点， 构成的赫夫曼树可以有多种形态， 但是最小 WPL 值是唯一的。

![demo](https://images2017.cnblogs.com/blog/1060770/201801/1060770-20180117231626740-1383924626.png)

### 哈夫曼编码

[baidu](https://baike.baidu.com/item/%E5%93%88%E5%A4%AB%E6%9B%BC%E7%BC%96%E7%A0%81)

在计算机数据处理中，哈夫曼编码使用变长编码表对源符号（如文件中的一个字母）进行编码，其中变长编码表是通过一种评估来源符号出现机率的方法得到的，**出现机率高的字母使用较短的编码**，反之出现机率低的则使用较长的编码，这便使编码之后的字符串的平均长度、期望值降低，从而达到无损压缩数据的目的。

例如，在英文中，e 的出现机率最高，而 z 的出现概率则最低。当利用哈夫曼编码对一篇英文进行压缩时，e 极有可能用一个比特来表示，而 z 则可能花去 25 个比特（不是 26）。用普通的表示方法时，每个英文字母均占用一个字节，即 8 个比特。二者相比，e 使用了一般编码的 1/8 的长度，z 则使用了 3 倍多。倘若我们能实现对于英文中各个字母出现概率的较准确的估算，就可以**大幅度提高无损压缩的比例**。

### 构造

假设有 n 个权值，则构造出的哈夫曼树有 n 个叶子结点。 n 个权值分别设为 w1、w2、…、wn，则哈夫曼树的构造规则为：

- (1) 将 w1、w2、…，wn 看成是有 n 棵树的森林（每棵树仅有一个结点）；
- (2) 在森林中选出两个根结点的权值最小的树合并，作为一棵新树的左、右子树，且新树的根结点权值为其左、右子树根结点权值之和；
- (3) 从森林中删除选取的两棵已经进行过合并树，并将新树加入森林；
- (4) 重复 (2)、(3) 步，直到森林中只剩一棵树为止，该树即为所求得的哈夫曼树。

### 多叉哈夫曼树

哈夫曼树也可以是 k 叉的，只是在构造 k 叉哈夫曼树时需要先进行一些调整。构造哈夫曼树的思想是**每次选 k 个权重最小的元素来合成一个新的元素**，该元素权重为 k 个元素权重之和。但是当 k 大于 2 时，按照这个步骤做下去可能到最后剩下的元素少于 k 个。解决这个问题的办法是假设已经有了一棵哈夫曼树（且为一棵满 k 叉树），则可以计算出其叶节点数目为 (k-1)nk+1, 式子中的 nk 表示子节点数目为 k 的节点数目。于是对给定的 n 个权值构造 k 叉哈夫曼树时，可以先考虑增加一些权值为 0 的叶子节点，使得叶子节点总数为 (k-1)nk+1 这种形式，然后再按照哈夫曼树的方法进行构造即可。

### 哈夫曼树的构建

我可真是一个挖坑专业户，计算机的坑是填不满的 hhh

TODO：哈夫曼树的构建 

### 哈夫曼树与哈夫曼编码

TODO ：数据压缩

TODO： 数据解压缩

## 树的计数

翻书的时候遇到了一个醒目的标题，很快啊，他就哟啊被我拿下了

::: tip 问题
具有 n 个节点的不同形态的树有几颗
:::

（没谷歌之前：链算一层，然后二层的树就有好几种形态，每一个节点都可以当作根节点，并且根节点还可能不止一个，每个节点拥有的子树个数也有 n 种情况，非常乱哇咔咔，目测递归解决，但是我不会）

### 开始

卡特兰数（原来邓俊辉讲过。)

> 如果两棵树中各个结点的位置都一一对应，可以说这两棵树相似。如果两棵树不仅相似，而且对应结点上的数据也相同，就可以说这两棵树等价。本节中，形态不同的树指的是互不相似的树。

对于任意一棵普通树，通过 [孩子兄弟表示法](http://data.biancheng.net/view/198.html) 的转化，都可以找到唯一的一棵二叉树与之对应。所以本节研究的题目也可以转化成：n 个结点可以构建多少种形态不同的二叉树。

（好家伙，我举然不知道，我学了个啥？？？我是废物好吧）

每一棵普通树对应的都是一棵没有右子树的二叉树，所以对于 n 个结点的树来说，树的形态改变是因为除了根结点之外的其它结点改变形态得到的，所以，n 个结点构建的形态不同的树与之对应的是 n-1 个结点构建的形态不同的二叉树。

如果 tn 表示 n 个结点构建的形态不同的树的数量，bn 表示 n 个结点构建的形态不同的二叉树的数量，则两者之间有这样的关系：tn=bn-1。

**每一棵普通树对应的都是一棵没有右子树的二叉树**？，所以对于 n 个结点的树来说，树的形态改变是因为除了根结点之外的其它结点改变形态得到的，所以，**n 个结点构建的形态不同的树与之对应的是 n-1 个结点构建的形态不同的二叉树**？

对于具有 n（ n>1 ）个结点的二叉树来说，都可以看成是一个根结点、由 i 个结点组成的左子树和由 n-i-1 个结点组成的右子树。

### 推理

最直接的一种方法就是推理。当 n=0 时，只能构建一棵空树；当 n=2 时，可以构建 2 棵形态不同的二叉树，如图 1（A）；当 n=3 时，可以构建 5 棵形态互不相同的二叉树，如图

![demo](http://data.biancheng.net/uploads/allimg/170905/2-1FZ5104043937.png)

不太懂，先写结论

递推公式：

$$
\begin{cases}
b_0=1\\
b_n=\sum^{n-1}_{i=0}b_ib_{n-i-1}
\end{cases}
$$

通过对公式一步步的数学推算，最后得出，含有 n 个结点的不相似的二叉树的数量为：

$$b_n =\cfrac{1}{n+1} \cdot C^{n}_{2n}$$

### 根据还原二叉树得到公式：

http://data.biancheng.net/view/35.html
## 邻接表
![demo](http://data.biancheng.net/uploads/allimg/190106/2-1Z106140Q33H.gif)

拿顶点 V1 来说，与其相关的邻接点分别为 V2 和 V3，因此存储 V1 的链表中存储的是 V2 和 V3 在数组中的位置下标 1 和 2。

从储存示例图中可以看出，存储各顶点的节点结构分为两部分，数据域和指针域。数据域用于存储顶点数据信息，指针域用于链接下一个节点
![demo](http://data.biancheng.net/uploads/allimg/190106/2-1Z106140S61c.gif)
在实际应用中，除了图 2 这种节点结构外，对于用链接表存储网（边或弧存在权）结构，还需要节点存储权的值 节点结构就需要变成三部分
### 邻接表计算顶点的出度和入度

使用邻接表计算无向图中顶点的入度和出度会非常简单，只需从数组中找到该顶点然后统计此链表中节点的数量即可。

而使用邻接表存储有向图时，通常各个顶点的链表中存储的都是以该顶点为弧尾的邻接点，因此通过统计各顶点链表中的节点数量，只能计算出该顶点的出度，而无法计算该顶点的入度。

对于利用邻接表求某顶点的入度，有两种方式：
遍历整个邻接表中的节点，统计数据域与该顶点所在数组位置下标相同的节点数量，即为该顶点的入度；

建立一个逆邻接表，该表中的各顶点链表专门用于存储以此顶点为弧头的所有顶点在数组中的位置下标。比如说，建立一张图 1a) 对应的逆邻接表，如图所示：
![demo](http://data.biancheng.net/uploads/allimg/190106/2-1Z10614093LF.gif)

对于具有 n 个顶点和 e 条边的无向图，邻接表中需要存储 n 个头结点和 2e 个表结点。在图中边或者弧稀疏的时候，使用邻接表要比前一节介绍的邻接矩阵更加节省空间。

## 十字链表

与邻接表不同，十字链表法仅适用于存储有向图和有向网。不仅如此，十字链表法还**改善了邻接表计算图中顶点入度的问题。**   

可以看成是将有向图的邻接表和逆邻接表结合起来得到的一种链表。在十字链表中，对应于有向图中每一条弧都有一个结点，对应于每个定顶点也有一个结点。  

由此可以看出，十字链表实质上就是为每个顶点建立两个链表，分别存储以该顶点为弧头的所有顶点和以该顶点为弧尾的所有顶点。
### 构成
用链表模拟矩阵的行（或者列，这可以根据个人喜好来定），然后，再构造代表列（或者是行）的链表，将每一行中的元素节点插入到对应的列中去。十字链表的逻辑结构就像是一个围棋盘（没见过，你就想一下苍蝇拍，这个总见过吧！），而非零元就好像是在棋盘上放的棋子，总共占的空间就是，确定那些线的表头节点和那些棋子代表的非零元节点。最后，我们用一个指针指向这个棋盘，这个指针就代表了这个稀疏矩阵。

存储稀疏图的一种方式

![demo](http://data.biancheng.net/uploads/allimg/170720/2-1FH0101K6448.png)
![demo](http://data.biancheng.net/uploads/allimg/170720/2-1FH010305Y06.png)

## 邻接多重表

无向图的存储可以使用邻接表，但在实际使用时，如果想对图中某顶点进行实操（修改或删除），由于邻接表中存储该顶点的节点有两个，因此需要操作两个节点。

> 为了提高在无向图中操作顶点的效率 注意，邻接多重表仅适用于存储无向图或无向网。

邻接多重表是无向图的一种存储方式。邻接多重表是邻接表的改进，它把边的两个顶点存放在边表结点中，所有依附于同一个顶点的边串联在同一链表中，由于每条边依附于两个顶点，则每个边表结点同时链接在两个链表中。 

### 简介

邻接多重表 (adjacent multiList) 是无向图（网）的另一种链式存储结构。在此存储结构中，图的顶点信息存放在顶点数组中，数组元素有两个域：data 域，存放与顶点相关的信息；firstedge 域，指向一个单链表，此单链表存储所有依附于该顶点的边的信息。这些单链表的一个表结点对应一条边，表结点有六个域：mark 为标志域，用来标记该边是否被访问过；ivex 和 jvex 分别存放该边两个顶点在图中的位置；info 域存放该边相关的信息，实际上就是弧的权值，对于无向图，info 域可省略；ilink 指向下一条依附于顶点 ivex 的边对应的表结点；jlink 指向下一条依附于顶点 jvex 的边对应的表结点。 

### 应用

解决邻接表存储无向图时同一条边要存储两次的问题。
邻接多重表主要用于存储无向图。因为如果用邻接表存储无向图，每条边的两个边结点分别在以该边所依附的两个顶点为头结点的链表中，这给图的某些操作带来不便。例如，对已访问过的边做标记，或者要删除图中某一条边等，都需要找到表示同一条边的两个结点。因此，在进行这一类操作的无向图的问题中，采用邻接多重表作存储结构更为适宜。

## 三元组

[百度百科](https://baike.baidu.com/item/%E4%B8%89%E5%85%83%E7%BB%84)

> 下面基本就是图部分的未知部分了，还挺多的

## 无向图的连通分量和生成树
TODO 无向图的连通分量和生成树
## 强连通分量

强连通的定义是：有向图 G 强连通是指，G 中任意两个结点连通。

强连通分量（Strongly Connected Components，SCC）的定义是：极大的强连通子图。

### Tarjan 算法

https://byvoid.com/zhs/blog/scc-tarjan/

arjan 发明了很多算法结构。不少他发明的算法都以他的名字命名，以至于有时会让人混淆几种不同的算法。
比如求各种连通分量的 Tarjan 算法，求 LCA（Lowest Common Ancestor，最近公共祖先）的 Tarjan 算法。
并查集、Splay、Toptree 也是 Tarjan 发明的。

我们这里要介绍的是在有向图中求强连通分量的 Tarjan 算法。

### DFS 生成树

在介绍该算法之前，先来了解 DFS 生成树 ，我们以下面的有向图为例：

![demo](https://oi-wiki.org/graph/images/scc1.png)

DFS 生成树与强连通分量之间的关系。
https://oi-wiki.org/graph/scc/

## 最小生成树

> 心浮气躁的时候就去睡觉！，复活完成

之前有写过 [最小生成树的总结](https://konng.now.sh/posts/1970/01/01/_06-%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91.html)，依然不能手写，但是考试好像会考到 ，所以完善一次笔记

## 关节点 和重连通分量

就是一些花里胡哨的定义，见过了解了即可

　相关定义：假若在删去顶点 v 以及和 v 相关联的各边之后，将图的一个连通分量分割成两个或两个以上的连通分量，则称顶点 v 为该图的一个关节点。一个没有关节点的连通图称为重连通图。在重连通图上，任意一对顶点之间至少存在两条路径，则在删去某个顶点以及依附于该顶点的各边时也不破坏图的连通性。若在连通图上至少删除 k 个顶点才能破坏图的连通性，则称此图的连通度为 k.

判断图是否是重连通的，可以先利用深度优先搜索求得图的关节点，一个没有关节点的图便是重连通的。由深度优先生成树可得出两类关节点的特性：

1. 若生成树的根有**两颗或两颗以上的子树**，则此根顶点必为关节点。因为。若删去根顶点，生成树便变成生成森林。如示意图中的顶点 A
2. 若生成树中某个非叶子顶点 v, 其某棵子树的根和子树中的其他结点均没有指向 v 的祖先的回边，则 v 为关节点。因为，若删去 v, 则其子树和图的其他部分被分割开来

## 有向无环图

DAG 有向无环图 Directed acyclic graph
有向无环图的生成树个数等于入度非零的节点的入度积。

[百度百科](https://baike.baidu.com/item/%E6%9C%89%E5%90%91%E6%97%A0%E7%8E%AF%E5%9B%BE)
在图论中，如果一个有向图无法从某个顶点出发经过若干条边回到该点，则这个图是一个有向无环图（DAG图）。
因为有向图中一个点经过两种路线到达另一个点未必形成环，因此有向无环图未必能转化成树，但任何有向树均为有向无环图。

## 拓扑排序

[拓扑排序 oi Wiki](https://oi-wiki.org/graph/topo/)

拓扑排序的目标是将所有节点排序，使得排在前面的节点不能依赖于排在后面的节点。

> 【百度百科】 对一个有向无环图(Directed Acyclic Graph简称DAG)G进行拓扑排序，是将G中所有顶点排成一个线性序列，使得图中任意一对顶点u和v，若边<u,v>∈E(G)，则u在线性序列中出现在v之前。通常，这样的线性序列称为满足拓扑次序(Topological Order)的序列，简称拓扑序列。简单的说，由某个集合上的一个偏序得到该集合上的一个全序，这个操作称之为拓扑排序。 

### Kahn 算法

![demo](https://oi-wiki.org/graph/images/topo.png)

对其排序的结果就是：2 -> 8 -> 0 -> 3 -> 7 -> 1 -> 5 -> 6 -> 9 -> 4 -> 11 -> 10 -> 12


``` cpp

```
### DFS 算法

``` cpp
```
### 应用

拓扑排序可以用来判断图中是否有环，
还可以用来判断图是否是一条链。

## 关键路径 (AOE,AOV)

> 【百度百科】 关键路径通常（但并非总是）是决定项目工期的进度活动序列。它是项目中最长的路径，即使很小浮动也可能直接影响整个项目的最早完成时间。关键路径的工期决定了整个项目的工期，任何关键路径上的终端元素的延迟在浮动时间为零或负数时将直接影响项目的预期完成时间（例如在关键路径上没有浮动时间）。 [2]  但特殊情况下，如果总浮动时间大于零，则有可能不会影响项目整体进度。  
> 一个项目可以有多个、并行的关键路径。另一个总工期比关键路径的总工期略少的一条并行路径被称为次关键路径。最初，关键路径方法只考虑终端元素之间的逻辑依赖关系。关键链方法中增加了资源约束。关键路径方法是由杜邦公司发明的。

### 步骤

从开始顶点 v1 出发，令 ve(1)=0，按拓扑有序序列求其余各顶点的可能最早发生时间。
如果得到的拓朴有序序列中顶点的个数小于网中顶点个数n，则说明网中有环，不能求出关键路径，算法结束。
B、从完成顶点出发，令，按逆拓扑有序求其余各顶点的允许的最晚发生时间：
C、求每一项活动ai（1 ≤ i ≤ m）的最早开始时间e(i)=ve(j)，最晚开始时间l(i)=vl(k)-dut(<j,k>) 。
若某条弧满足 e(i)=l(i) ，则它是关键活动。

### AOE 网

用顶点表示事件，弧表示活动，弧上的权值表示活动持续的时间的有向图叫AOE（Activity On Edge Network）网。在建筑学中也称为关键路线。AOE网常用于估算工程完成时间。

### 算法

（1） 输入e条弧<j,k>，建立AOE网的存储结构；
（2） 从源点v1出发，令ve(1)=0，求 ve(j) ,2<=j<=n；
（3） 从汇点vn出发，令vl(n)=ve(n)，求 vl(i), 1<=i<=n-1；
（4） 根据各顶点的ve和vl值，求每条弧s（活动）的最早开始时间e(s)和最晚开始时间l(s)，其中e(s)=l(s)的为关键活动。
求关键路径是在拓扑排序的前提下进行的，不能进行拓扑排序，自然也不能求关键路径。
算法分析
（1） 求关键路径必须在拓扑排序的前提下进行，有环图不能求关键路径；
（2） 只有缩短关键活动的工期才有可能缩短工期；
（3） 若一个关键活动不在所有的关键路径上，减少它并不能减少工期；
（4） 只有在不改变关键路径的前提下，缩短关键活动才能缩短整个工期。

## 从某个远点到其余各个顶点的最短路径

### floyd算法

是用来求任意两个结点之间的最短路的。
复杂度比较高，但是常数小，容易实现。（我会说只有三个 for 吗？）
适用于任何图，不管有向无向，边权正负，但是最短路必须存在。（不能有个负环）

a.从任意一条单边路径开始。所有两点之间的距离是边的权，如果两点之间没有边相连，则权为无穷大。 　　
b.对于每一对顶点 u 和 v，看看是否存在一个顶点 w 使得从 u 到 w 再到 v 比己知的路径更短。如果是更新它。

### Bellman-Ford 算法

### 队列优化：SPFA

### Dijkstra 算法

这种算法只适用于非负权图，但是时间复杂度非常优秀。

也是用来求单源最短路径的算法。

1)算法思想：设G=(V,E)是一个带权有向图，把图中顶点集合V分成两组，第一组为已求出最短路径的顶点集合（用S表示，初始时S中只有一个源点，以后每求得一条最短路径 , 就将加入到集合S中，直到全部顶点都加入到S中，算法就结束了），第二组为其余未确定最短路径的顶点集合（用U表示），按最短路径长度的递增次序依次把第二组的顶点加入S中。在加入的过程中，总保持**从源点v到S中各顶点的最短路径长度不大于从源点v到U中任何顶点的最短路径长度**。此外，每个顶点对应一个距离，S中的顶点的距离就是从v到此顶点的最短路径长度，U中的顶点的距离，是从v到此顶点只包括S中的顶点为中间顶点的当前最短路径长度。

![demo](https://pic002.cnblogs.com/images/2012/426620/2012073019540660.gif)

实例：

![demo](https://pic002.cnblogs.com/images/2012/426620/2012073019593375.jpg)

![demo](https://pic002.cnblogs.com/images/2012/426620/2012073020014941.jpg)

### Johnson 全源最短路径算法
### D´Esopo-Pape 算法
## k 短路 

## 二叉排序树的构造过程

## B-树和 B+树
[B-](https://ivanzz1001.github.io/records/post/data-structure/2018/06/15/ds-btree)
[B+](https://ivanzz1001.github.io/records/post/data-structure/2018/06/16/ds-bplustree)
[B 树和B+树](https://juejin.cn/post/6844903908985274381)
[插入删除](https://www.cnblogs.com/nullzx/p/8729425.html)

## 红黑树

[红黑树：30张图带你彻底理解红黑树](https://www.jianshu.com/p/e136ec79235c)
[rbt](https://ivanzz1001.github.io/records/post/data-structure/2018/06/24/ds-red-black-tree)

## 键树又称为数字查找树

[键树](https://ivanzz1001.github.io/records/post/data-structure/2018/07/15/ds-dstree)

## 哈希表

> 【百度百科】https://baike.baidu.com/item/%E5%93%88%E5%B8%8C%E8%A1%A8
> https://oi-wiki.org/ds/hash/

